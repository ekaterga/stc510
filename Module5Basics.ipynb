{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAmd+oXgD8tHRyRx4mMEg6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekaterga/stc510/blob/main/Module5Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "78u_CesqFAJO"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I loaded the dat from the JSON file as a dictionary and converted it to a dataframe"
      ],
      "metadata": {
        "id": "F7glM6ekISAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('jeopardy.json', 'r') as file:\n",
        "    data_dict = json.load(file)"
      ],
      "metadata": {
        "id": "LkVhK4SWFIF7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame(data_dict)"
      ],
      "metadata": {
        "id": "nL96YCbkFdbk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I wanted to double check that everything looked good. Then I converted the values to strings in order to remove the punctuation in order to convert the values into integers"
      ],
      "metadata": {
        "id": "ihsG0OWZIbpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQpiMQQRFkQT",
        "outputId": "dbe11e89-a692-4501-f48c-098bc34fe00a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               category    air_date  \\\n",
            "0                               HISTORY  2004-12-31   \n",
            "1       ESPN's TOP 10 ALL-TIME ATHLETES  2004-12-31   \n",
            "2           EVERYBODY TALKS ABOUT IT...  2004-12-31   \n",
            "3                      THE COMPANY LINE  2004-12-31   \n",
            "4                   EPITAPHS & TRIBUTES  2004-12-31   \n",
            "...                                 ...         ...   \n",
            "216925                   RIDDLE ME THIS  2006-05-11   \n",
            "216926                        \"T\" BIRDS  2006-05-11   \n",
            "216927           AUTHORS IN THEIR YOUTH  2006-05-11   \n",
            "216928                       QUOTATIONS  2006-05-11   \n",
            "216929                   HISTORIC NAMES  2006-05-11   \n",
            "\n",
            "                                                 question  value  \\\n",
            "0       'For the last 8 years of his life, Galileo was...   $200   \n",
            "1       'No. 2: 1912 Olympian; football star at Carlis...   $200   \n",
            "2       'The city of Yuma in this state has a record a...   $200   \n",
            "3       'In 1963, live on \"The Art Linkletter Show\", t...   $200   \n",
            "4       'Signer of the Dec. of Indep., framer of the C...   $200   \n",
            "...                                                   ...    ...   \n",
            "216925  'This Puccini opera turns on the solution to 3...  $2000   \n",
            "216926  'In North America this term is properly applie...  $2000   \n",
            "216927  'In Penny Lane, where this \"Hellraiser\" grew u...  $2000   \n",
            "216928  'From Ft. Sill, Okla. he made the plea, Arizon...  $2000   \n",
            "216929  'A silent movie title includes the last name o...   None   \n",
            "\n",
            "                                answer             round show_number  \n",
            "0                           Copernicus         Jeopardy!        4680  \n",
            "1                           Jim Thorpe         Jeopardy!        4680  \n",
            "2                              Arizona         Jeopardy!        4680  \n",
            "3                          McDonald\\'s         Jeopardy!        4680  \n",
            "4                           John Adams         Jeopardy!        4680  \n",
            "...                                ...               ...         ...  \n",
            "216925                        Turandot  Double Jeopardy!        4999  \n",
            "216926                      a titmouse  Double Jeopardy!        4999  \n",
            "216927                    Clive Barker  Double Jeopardy!        4999  \n",
            "216928                        Geronimo  Double Jeopardy!        4999  \n",
            "216929  Grigori Alexandrovich Potemkin   Final Jeopardy!        4999  \n",
            "\n",
            "[216930 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['value'] = data['value'].astype(str).replace('[\\$,]', '', regex=True)\n",
        "data['value'] = pd.to_numeric(data['value'], errors='coerce').fillna(0).astype(int)"
      ],
      "metadata": {
        "id": "3-tROqrBGjvK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['value'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIpAwgdtHd6_",
        "outputId": "b360b8a8-a85b-4589-e480-3a51b0824aa8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0          200\n",
            "1          200\n",
            "2          200\n",
            "3          200\n",
            "4          200\n",
            "          ... \n",
            "216925    2000\n",
            "216926    2000\n",
            "216927    2000\n",
            "216928    2000\n",
            "216929       0\n",
            "Name: value, Length: 216930, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I made any question equal to or more than $800 to high value"
      ],
      "metadata": {
        "id": "HNBqTjY0I0HB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['value_class'] = data['value'].apply(lambda x: 'high' if x >= 800 else 'low')"
      ],
      "metadata": {
        "id": "PPS2G6SOGpQ2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I split the data into training and testing sets."
      ],
      "metadata": {
        "id": "c4gQRRYqJLyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data['question'], data['value_class'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zdTsJMYAGrQE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then I vectorized the test data and trained the Naive Bayes classifier"
      ],
      "metadata": {
        "id": "zUuvJ2VWJPbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "QZrynhFxGuxC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next I had it make a predicition on the test set, evaluted the classifier, and performed a test question that I had the answer for in the dataset."
      ],
      "metadata": {
        "id": "ckfO_cXdJXFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "rvP9OtKyGyPN",
        "outputId": "717e179a-1141-44e9-d596-a3374a3cd01c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = nb_classifier.predict(X_test_vec)"
      ],
      "metadata": {
        "id": "Q79omDdgG00N"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UyWUkt1G21Z",
        "outputId": "a1988a63-c155-4e0b-b095-a261c39d806e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.595514682155534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = 'This lake lies in a caldera formed when Oregons Mount Mazama volcano collapsed 7,000 years ago'\n",
        "question_vec = vectorizer.transform([question])\n",
        "prediction = nb_classifier.predict(question_vec)\n",
        "print(f'Prediction for \"{question}\": {prediction}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGjaCjxxG6CK",
        "outputId": "57004b73-e6b9-4266-ce25-c90ceec4fc44"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for \"This lake lies in a caldera formed when Oregons Mount Mazama volcano collapsed 7,000 years ago\": ['high']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code accurately predicted the value for this question"
      ],
      "metadata": {
        "id": "Ex0C2NyBLF1w"
      }
    }
  ]
}